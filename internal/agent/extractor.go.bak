package agent

import (
	"encoding/json"
	"fmt"
	"log"

	"github.com/ccastromar/aos-banking-v2/internal/config"
	"github.com/ccastromar/aos-banking-v2/internal/llm"
)

type Extractor struct {
	llm llm.Client
}

func NewExtractor(client llm.Client) *Extractor {
	return &Extractor{llm: client}
}

// ExtractParams analiza el mensaje de usuario y extrae los campos requeridos.
func (e *Extractor) ExtractParams(intent config.Intent, userMsg string) (map[string]string, error) {
	if len(intent.RequiredParams) == 0 {
		return map[string]string{}, nil
	}

	log.Printf("[Extractor] extrayendo parámetros para intent=%s", intent.Type)

	// Construimos prompt
	prompt := "Extrae los siguientes parámetros del mensaje:\n"
	for _, p := range intent.RequiredParams {
		prompt += "- " + p + "\n"
	}
	prompt += fmt.Sprintf("\nMensaje: \"%s\"\n\n", userMsg)
	prompt += "Devuelve SOLO un JSON plano con string values."

	raw, err := e.llm.Chat(prompt)
	if err != nil {
		return nil, err
	}

	// El LLM puede devolver texto alrededor → lo limpiamos al vuelo
	var params map[string]string
	if err := json.Unmarshal([]byte(raw), &params); err != nil {
		log.Printf("[Extractor] WARNING: JSON directo falló. Intentamos limpiar.")
		raw = llm.ExtractJSON(raw)
		if err := json.Unmarshal([]byte(raw), &params); err != nil {
			return nil, fmt.Errorf("error parseando JSON LLM: %v -- contenido: %s", err, raw)
		}
	}

	return params, nil
}
